{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where is your GAN? Генеративно-состязательная нейросеть: ваша первая модель на PyTorch\n",
    "\n",
    "Данный материал представляет собой незначительно сокращенный перевод публикации Ренато Кандидо [Generative Adversarial Networks: Build Your First Models](https://realpython.com/generative-adversarial-networks/).\n",
    "\n",
    "Генеративно-состязательные сети (англ. Generative adversarial networks, сокр. GAN) – [нейронные сети](https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C), которые умеют генерировать изображения, музыку, речь и тексты, похожие на те, что делают люди. \n",
    "\n",
    "GAN были активной темой исследований последних лет. Директор по исследованиям в области искусственного интеллекта в Facebook Ян Лекан назвал состязательное обучение «самой интересной идеей в области машинного обучения за последние 10 лет». Ниже вы узнаете, как работают GAN и создадите две собственные модели. Для работы с моделями будет использоваться [фреймворк глубокого обучения](https://proglib.io/p/dl-frameworks) PyTorch.\n",
    "\n",
    "# Что такое генеративно-состязательная нейросеть?\n",
    "\n",
    "[Генеративно-состязательные сети](https://ru.wikipedia.org/wiki/%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%BE-%D1%81%D0%BE%D1%81%D1%82%D1%8F%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C) – это модели машинного обучения, умеющие имитировать заданное распределение данных. Впервые они были предложены в [статье NeurIPS](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) 2014 г. экспертом в глубоком обучении Яном Гудфеллоу и его коллегами.\n",
    "\n",
    "GAN состоят из двух нейронных сетей, одна из которых обучена генерировать данные, а другая обучена отличать ложные данные от реальных (отсюда и «состязательный» характер модели). GAN показывают впечатляющие результаты в отношении генерации изображений и видео, такие как:\n",
    "* Перенос стилей ([CycleGAN](https://github.com/junyanz/CycleGAN/)) – преобразование одного изображения в соответствии со стилем других изображений (например, картин известного художника)\n",
    "* Генерация человеческих лиц ([StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)), реалистичные примеры которых вы можете найти на сайте [This Person Does Not Exist](https://www.thispersondoesnotexist.com/).\n",
    "\n",
    "GAN и другие структуры, генерирующие данные, называют **генеративными моделями** в противовес более широко изученным **дискриминативным моделям**. Прежде чем погрузиться в GAN, посмотрим на различия между этими двумя типами моделей.\n",
    "\n",
    "# Сравнение дискриминативных и генеративных моделей\n",
    "\n",
    "Дискриминативные модели используются для большинства [обучения с учителем](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC) на [классификацию](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8) или [регрессию](https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7). В качестве примера проблемы классификации предположим, что вы хотите обучить [модель классификации изображений рукописных цифр от 0 до 9](https://proglib.io/p/neural-network-course). Для этого вы можете использовать маркированный набор данных, содержащий изображения рукописных цифр и связанные метки, указывающие соответствие цифр и изображений.\n",
    "\n",
    "В процессе обучения для настройки параметров модели вы будете использовать специальный алгоритм. Его цель состоит в том, чтобы [минимизировать функцию потерь](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C) – критерий раскхождения между истинным значением оцениваемого параметра и его оценкой. После фазы обучения вы можете использовать модель для классификации нового изображения рукописной цифры, сопоставив входному изображению наиболее вероятную цифру, как показано на рисунке ниже.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_discriminative.9c22a1cd877d.png)\n",
    "*Схема обучения дискриминативной модели*\n",
    "\n",
    "Дискриминативную модель для задач классификации можно представить, как «черный ящик», который использует обучающие данные для изучения границ между классами. Найденные границы далее используются моделью, чтобы различить входные данные – предсказать их класс. В математическом отношении дискриминативные модели изучают [условную вероятность](https://ru.wikipedia.org/wiki/%D0%A3%D1%81%D0%BB%D0%BE%D0%B2%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C) $P(y|x)$ наблюдения $y$ при заданном входе $x$.\n",
    "\n",
    "Дискриминативные модели это не обязательно нейронные сети. К ним также относятся такие модели машинного обучения, как [логистическая регрессия](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F) и [метод опорных векторов (SVM)](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2).\n",
    "\n",
    "В то время как дискриминативные модели используются для контролируемого обучения, генеративные модели часто используют неразмеченный набор данных, то есть могут рассматриваться как форма [обучения без учителя](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B1%D0%B5%D0%B7_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F). Используя набор данных из рукописных цифр, вы можете обучить генеративную модель для генерации новых цифр. На этапе обучения модель использует определенный алгоритм для настройки параметров модели, чтобы также минимизировать функцию потерь и определить распределение вероятностей обучающего набора.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_generative.5f01c08f5208.png)\n",
    "*Схема обучения генеративной модели*\n",
    "\n",
    "В отличие от дискриминативных моделей, генеративные модели изучают свойства [функции вероятности](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B8) $P(x)$ входных данных $x$. В результате они порождают не предсказание, а новый объект со свойствами, родственными обучающему набору данных.\n",
    "\n",
    "---\n",
    "\n",
    "**Примечание**. Генеративные модели также можно использовать и для размеченных наборов данных. Их также можно использовать для задач классификации, но в целом дискриминативные модели работают лучше, когда речь идет о классификации. \n",
    "\n",
    "Вы можете найти больше информации об относительных сильных и слабых сторонах  классификаторов в статье [«Дискриминативные и генеративные классификаторы: сравнение логистической регрессии и наивного байесовского алгоритма»](https://realpython.com/generative-adversarial-networks/) (англ.).\n",
    "\n",
    "---\n",
    "\n",
    "Помимо GAN существуют другие генеративные модели архитектуры:\n",
    "* [Машина Больцмана](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%B0_%D0%91%D0%BE%D0%BB%D1%8C%D1%86%D0%BC%D0%B0%D0%BD%D0%B0)\n",
    "* [Автокодировщик](https://ru.wikipedia.org/wiki/%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA)\n",
    "* [Скрытая марковская модель](https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D1%80%D1%8B%D1%82%D0%B0%D1%8F_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C)\n",
    "* Модели, предсказывающие следующее слово в последовательности, например, [GPT-2](https://en.wikipedia.org/wiki/OpenAI#GPT-2)\n",
    "\n",
    "Тем не менее, в последнее время GAN привлекли наибольшее внимание общественности благодаря впечатляющим результатам в генерации изображений и видео. Поэтому остановимся на ее устройстве подробнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура генеративно-состязательных нейросетей\n",
    "\n",
    "Генеративно-состязательная сеть это на самом деле не одна сеть, а две: генератор и дискриминатор. Роль **генератора** состоит в том, чтобы на основе реальной выборки сгенерировать набор данных, напоминающий реальные данные. **Дискриминатор** в свою очередь обучен оценивать вероятность того, что данный образец получен из реальных данных, а не предоставлен генератором. Состязательность GAN заключается в том, что генератор и дискриминатор играют в кошки-мышки: генератор пытается обмануть дискриминатор, а дискриминатор старается лучше идентифицировать сгенерированные выборки.\n",
    "\n",
    "Чтобы понять, как работает обучение GAN, рассмотрим игрушечный пример с набором данных, состоящим из двумерных выборок $(x_1, x_2)$, с $x_1$ в интервале от $0$ до $2π$ и $x_2 = sin(x_1)$, как показано на следующем рисунке.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_x1x2.f8a39d8ff58a.png)\n",
    "\n",
    "Общая структура GAN для генерации пар $(x̃_1, x̃_2)$, напоминающих точки набора данных, показана на следующем рисунке.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_gan.4f0f744c7999.png)\n",
    "\n",
    "Генератор $G$ получает на вход пары случайных чисел ($z_1, z_2$), преобразуя их так, чтобы они напоминали реальные выборки. Структура нейронной сети $G$ может быть произвольной, например, [многослойный персептрон](https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD_%D0%A0%D1%83%D0%BC%D0%B5%D0%BB%D1%8C%D1%85%D0%B0%D1%80%D1%82%D0%B0) (MLP) или [сверточная нейронная сеть](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C) (CNN).\n",
    "\n",
    "На вход дискриминатора $D$ попеременно поступают реальные образцы из обучающего набора данных и смоделированные образцы, предоставленные генератором $G$. Роль дискриминатора заключается в оценке вероятности того, что входные данные принадлежат реальному набору данных. То есть обучение выполняется таким образом, чтобы $D$ выдавал $1$, когда получает реальный образец, и $0$, когда получает сгенерированный образец.\n",
    "\n",
    "Как и в случае с генератором, вы можете выбрать любую структуру нейронной сети для $D$ с учетом размеров входных и выходных данных. В рассматриваемом примере ввод является двумерным, а выходные данные – [скаляром](https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D0%B0%D0%BB%D1%8F%D1%80%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B0) в диапазоне от 0 до 1.\n",
    "\n",
    "Процесс обучения GAN заключается в [минимаксной игре](https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B0%D0%BA%D1%81) двух игроков, в которой $D$ адаптирован для минимизации ошибки различия реального и сгенерированного образца, а $G$ адаптирован на максимизацию вероятности того, что $D$ допустит ошибку.\n",
    "\n",
    "На каждом этапе обучения происходит обновление параметров моделей $D$ и $G$. Чтобы обучить $D$, на каждой итерации мы помечаем некоторую выбору реальных образцов из обучающих данных, как 1, а выборку сгенерированных образцов, созданных $G$, как 0. Таким образом, для обновления параметров $D$, как показано на следующей схеме, можно использовать обычную схему обучения с учителем.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_train_discriminator.cd1a1e32764f.png)\n",
    "*Процесс обучения дискриминатора*\n",
    "\n",
    "Для каждой партии обучающих данных, содержащих помеченные реальные и сгенерированные образцы, мы обновляем набор параметров модели $D$, минимизируя тем самым функцию потерь. После того, как параметры $D$ обновлены, мы обучаем $G$ генерировать более качественные образцы. Набор параметров D «замораживается» на время обучения генератора.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_train_generator.7196c4f382ba.png)\n",
    "\n",
    "Когда $G$ будет генерировать образцы настолько хорошо, что $D$ начнет обманываться, выходная вероятность устремится к 1 – $D$ будет считать, что все образцы принадлежат к оригинальной выборке.\n",
    "\n",
    "Теперь, когда вы знаете, как в работает GAN, мы готовы реализовать свой собственный вариант нейросети, используя популярный фреймворк глубокого обучения PyTorch.\n",
    "\n",
    "# Ваша первая генеративно-состязательная нейросеть\n",
    "\n",
    "В качестве первого эксперимента с порождающими состязательными сетями мы реализуем пример, описанный в предыдущем разделе.\n",
    "\n",
    "![]()\n",
    "\n",
    "![]()\n",
    "\n",
    "![]()\n",
    "\n",
    "![]()\n",
    "\n",
    "![]()\n",
    "\n",
    "![]()\n",
    "\n",
    "[инструкция по установке](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы импортируем библиотеку PyTorch как `torch`. Из библиотеки мы отдельно импортируем компонент `nn` просто для того, чтобы было удобнее настраивать нейронные сети. Затем мы импортируем `math` для получения значения константы `pi` и инструмент построения графиков Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
