{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процессы и процессоры: машинное обучение на CPU, GPU и TPU (черновик)\n",
    "\n",
    "О различиях в тренировке моделей машинного обучения на различных типах процессоров.\n",
    "\n",
    "В основе множества моделей машинного обучение лежит перемножение матриц – и матричное, и поэлементное. От процесса обучения модели мы хотим при прочих равных условиях, чтобы оно производилось как можно быстрее.\n",
    "\n",
    "# Некоторые предварительные замечания об архитектуре процессоров\n",
    "## Арифметико-логическое устройство (ALU, АЛУ)\n",
    "Прежде чем, начать рассказ о CPU, GPU и TPU, стоит обсудить [арифметико-логических устройств](https://ru.wikipedia.org/wiki/%D0%90%D1%80%D0%B8%D1%84%D0%BC%D0%B5%D1%82%D0%B8%D0%BA%D0%BE-%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D1%83%D1%81%D1%82%D1%80%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%BE) (АЛУ, ALU). Именно ALU проводят базовые арифметические операции, в том числе суммирование и перемножение элементов матриц. Фактически ключевые отличия в CPU, GPU и TPU сводятся к разнице в количестве и взаимодействии ALU друг с другом и с памятью.\n",
    "\n",
    "## Центральное процессорное устройство (CPU)\n",
    "[CPU](https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80) – процессор общего назначения, выполняющий вычисления самого различного толка и координирующий работу устройств, из которых составлен компьютер. \n",
    "\n",
    "Большинство современных процессоров для персональных компьютеров основано на циклическом процессе *последовательной* обработки данных, изобретённой Джоном фон Нейманом. Узким местом соответствующей [архитектуры](https://ru.wikipedia.org/wiki/%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D1%84%D0%BE%D0%BD_%D0%9D%D0%B5%D0%B9%D0%BC%D0%B0%D0%BD%D0%B0) является *последовательное* обращение к АЛУ и к L1-кэшу. Это ограничивает общую пропускную способность.\n",
    "\n",
    "Основная причина появления [многоядерных процессоров](https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%8F%D0%B4%D0%B5%D1%80%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80) в середине 2000-х гг. – повышение производительности процессоров путем наращивания тактовой частоты достигло физического предела в связи с очень высоким уровнем тепловыделения и энергопотребления. Поэтому современные CPU имеют более одного ядра. Современные процессоры могут иметь более одного ядра, т.е. могут быть многоядерными. Многоядерные CPU способны выполнять одновременно несколько потоков команд.\n",
    "\n",
    "## GPU\n",
    "В архитектуре GPU содержатся тысячи АЛУ. Это позволяет проводить паралелльно множество операций сложения и умножения. Каждая из единиц большого массива данных обрабатывается одновременно. Поэтому пропускная способность GPU на порядки выше, чем у CPU.\n",
    "\n",
    "Однако GPU это тоже процессор общего назначения. Пусть он и работает с тысячами ALU, все равно для каждого вычисления необходимо обратиться к регистрам памяти, прочесть и сохранить результаты вычислений.\n",
    "\n",
    "## TPU\n",
    "[TPU](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BD%D0%B7%D0%BE%D1%80%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80_Google) не претендует на роль процессора общего назначения, это специализированная интегральная схема, разработанная Google для выполнения задач машинного обучения. Основа тензорного процессора — матричное устройство (matrix unit, MXU). Архитектура TPU называется [архитектурой конвейерного массива](https://en.wikipedia.org/wiki/Systolic_array) размеров 128x128. Чтобы наиболее полно использовать ресурсы оборудования TPU, размерность мини-выборки или признаков должна быть кратна такому массиву, а также числу ядер (обычно это 8). TPU только то и умеет, что складывать и перемножать матрицы. При этом промежуточные этапы вычисления сохраняются непосредственно в TPU.\n",
    "\n",
    "\n",
    "\n",
    "## Краткие выводы\n",
    "\n",
    "Тензорные процессоры оптимизированы под задачи, связанные с перемножением больших матриц (задачи глубокого обучения). Они умеют делать только это, но это они делают быстро. \n",
    "\n",
    "Характеристика | CPU | GPU | TPU\n",
    "---|---|---|---\n",
    "Универсальность | +++ | + | –\n",
    "Параллельные вычисления | – | + | +++\n",
    "Размер датасета | – | + | +\n",
    "\n",
    "\n",
    "# Отличительные особенности работы с GPU\n",
    "CUDA OpenCL\n",
    "\n",
    "Самым удобным в работе с GPU является то, что не приходится существенно переписывать код при переходе от CPU к GPU.\n",
    "\n",
    "# Отличительные особенности работы с TPU\n",
    "Тензорные процессоры TPU уже работают в нескольких основных продуктах Google, включая Translate, Photos, Search Assistant и Gmail. В 2018 г.  Google предоставил бесплатный доступ к своим тензорным процессорам на облачной платформе для машинного обучения Google Colab. \n",
    "\n",
    "Производительность третьего поколения TPU составляет 420 терафлопс ([триллионов операций с плавающей точкой в секунду](https://ru.wikipedia.org/wiki/FLOPS)), он имеет [8 TPU-ядер  и 128 ГБ памяти High Bandwidth Memory](https://cloud.google.com/tpu/docs/tpus).\n",
    "\n",
    "Ключевым отличием работы с TPU является необходимость подстраивать модель под TPU.\n",
    "\n",
    "## Работа с GPU или TPU на Colaboratory\n",
    "[Colaboratory](https://colab.research.google.com/) — облачная платформа от Google для продвижения технологий машинного обучения. Здесь можно получить бесплатно виртуальную машину с установленными популярными библиотеками TensorFlow, Keras, sklearn, pandas. На Colaboratory можно запускать Jupyter-блокноты, сохраняемые на Google Drive. То есть их можно распространять и организовывать через них совместную работу. \n",
    "\n",
    "Сессия работы на виртуальной машине ограничена. По истечении сессии нужно запускать машину заново. Однако промежуточные результаты можно сохранять на компьютер или в Google Drive. Для подключения ускорителя его достаточно выбрать в настройках. После изменения настроек произойдет перезапуск кернела.\n",
    "\n",
    "Работает с TensorFlow.\n",
    "\n",
    "Каждая сессия работы с TPU проходит на какой-то одной выделенной машине, которая меняется от сессии к сессии. Чтобы узнать текущий адрес, используем команду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "TPU_WORKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
